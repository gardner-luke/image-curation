{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c7efd1-7200-4e80-b16d-1f6fce192a81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register CLIP Text Embedding Model for Databricks Model Serving\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Create a custom MLflow PyFunc wrapper for CLIP text embeddings\n",
    "- Follow Databricks embedding model conventions for consistent API usage\n",
    "- Register the model to Unity Catalog for production use\n",
    "- Deploy the model to a Databricks Model Serving endpoint\n",
    "\n",
    "The resulting model endpoint can generate text embeddings using the same API pattern as `databricks-gte-large-en`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb2b1cbe-2273-4605-b8da-39f451eb7be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import necessary libraries for MLflow model creation and CLIP text embedding handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a305f62f-9146-4d59-9cf2-5546e29b361f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1a2f95-9da4-40ed-b8c9-3f58636821bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "Configure the model registration parameters for the text embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bef3b3-94b6-4072-9e7b-42aa1cd7b361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dataset Configuration - Update these values for your setup\n",
    "CATALOG_NAME = \"autobricks\"  # Your Unity Catalog name\n",
    "SCHEMA_NAME = \"agriculture\"   # Your schema name\n",
    "MODEL_NAME = \"clip_text_embedding\"  # Text embedding model name\n",
    "ENDPOINT_NAME = \"clip-text-embedding\"  # Text embedding endpoint name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56444d79-4dc6-41d9-9478-055b4b540295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define CLIP Text Embedding Model Class\n",
    "\n",
    "Create a custom MLflow PyFunc class that wraps CLIP for text embeddings following Databricks conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f79b436-eaab-4d61-9975-e3b8bc183273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CLIPTextEmbedding(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        from transformers import CLIPProcessor, CLIPModel\n",
    "        \n",
    "        self.model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def predict(self, context, model_input, params=None):\n",
    "        # Handle both string input and DataFrame input\n",
    "        if isinstance(model_input, str):\n",
    "            texts = [model_input]\n",
    "        elif isinstance(model_input, list):\n",
    "            texts = model_input\n",
    "        elif isinstance(model_input, pd.DataFrame):\n",
    "            # Handle DataFrame input - assume single column or 'input' column\n",
    "            if 'input' in model_input.columns:\n",
    "                texts = model_input['input'].tolist()\n",
    "            else:\n",
    "                texts = model_input.iloc[:, 0].tolist()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input type: {type(model_input)}\")\n",
    "        \n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            inputs = self.processor(text=[text], return_tensors=\"pt\", padding=True)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                text_features = self.model.get_text_features(**inputs)\n",
    "            \n",
    "            embedding = text_features.cpu().numpy().tolist()[0]\n",
    "            embeddings.append(embedding)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85b042d1-ad26-463f-bf01-0e05f564db46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register Text Embedding Model\n",
    "\n",
    "Register the CLIP text embedding model to Unity Catalog with proper MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d5dc980-d43a-4e2b-a143-fcb717e5ebda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "mlflow.set_experiment(f\"/Shared/clip_text_embedding_experiment\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Create model instance\n",
    "    model = CLIPTextEmbedding()\n",
    "    \n",
    "    # Create sample input for signature\n",
    "    sample_input = \"This is a sample text for embedding\"\n",
    "    \n",
    "    # Load model and generate sample output for signature\n",
    "    model.load_context(None)\n",
    "    sample_output = model.predict(None, sample_input)\n",
    "    \n",
    "    # Create signature\n",
    "    from mlflow.models import infer_signature\n",
    "    signature = infer_signature(sample_input, sample_output)\n",
    "    \n",
    "    # Define requirements\n",
    "    requirements = [\n",
    "        \"torch>=1.9.0\",\n",
    "        \"transformers>=4.21.0\"\n",
    "    ]\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"clip_text_model\",\n",
    "        python_model=model,\n",
    "        input_example=sample_input,\n",
    "        signature=signature,\n",
    "        pip_requirements=requirements,\n",
    "        registered_model_name=f\"{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Model registered as: {CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24da04ac-26bd-4250-9f87-741f74f275c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Serving Endpoint\n",
    "\n",
    "Deploy the registered text embedding model to a Databricks Model Serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c87b70d-b44e-4032-9aaa-d4cc3308cc16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Create serving endpoint\n",
    "full_model_name = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}\"\n",
    "\n",
    "w.serving_endpoints.create(\n",
    "    name=ENDPOINT_NAME,\n",
    "    config=EndpointCoreConfigInput(\n",
    "        served_entities=[\n",
    "            ServedEntityInput(\n",
    "                entity_name=full_model_name,\n",
    "                entity_version=\"1\",\n",
    "                workload_size=\"Small\",\n",
    "                scale_to_zero_enabled=True,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Text embedding endpoint created: {ENDPOINT_NAME}\")\n",
    "print(f\"Model: {full_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e97490-2a20-49a3-98fd-98c1c7509290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the Model\n",
    "\n",
    "Test the deployed text embedding model using Databricks standard API patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9645b5-b821-4bb1-a908-f94f2602e1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wait for endpoint to be ready, then test\n",
    "import time\n",
    "\n",
    "print(\"Waiting for endpoint to be ready...\")\n",
    "while True:\n",
    "    try:\n",
    "        endpoint = w.serving_endpoints.get(ENDPOINT_NAME)\n",
    "        if endpoint.state and endpoint.state.ready:\n",
    "            break\n",
    "        time.sleep(30)\n",
    "    except:\n",
    "        time.sleep(30)\n",
    "\n",
    "print(\"Endpoint ready, testing...\")\n",
    "\n",
    "# Test with standard Databricks embedding API pattern\n",
    "try:\n",
    "    response = w.serving_endpoints.query(\n",
    "        name=ENDPOINT_NAME,\n",
    "        input=\"This is a test sentence for text embedding\"\n",
    "    )\n",
    "    print(f\"Text embedding generated successfully: {len(response)} dimensions\")\n",
    "except Exception as e:\n",
    "    print(f\"Test failed: {e}\")\n",
    "\n",
    "print(f\"Text embedding model ready for use: {ENDPOINT_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01a - Register CLIP Text Embedding Model",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
