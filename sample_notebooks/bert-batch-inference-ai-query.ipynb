{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2b9fbd-0014-4bff-881a-ca1e2df85edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Batch inference using a BERT model for named entity recognition\n",
    "This notebook demonstrates how to do the following tasks:\n",
    "- Build a `pyfunc` model encapsulating a [BERT language model](https://github.com/google-research/bert) for named entity recognition (NER).\n",
    "- Deploy the [`pyfunc`](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html) model to a Mosaic AI Model Serving endpoint.\n",
    "- Perform batch inference using `ai_query`([AWS](https://docs.databricks.com/sql/language-manual/functions/ai_query.html) | [Azure](https://learn.microsoft.com/azure/databricks/sql/language-manual/functions/ai_query)) on the Mosaic AI Model Serving endpoint\n",
    "\n",
    "To test the model before deploying, run this notebook on a cluster with a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ff26da4-0635-4e9d-91dd-b084225f9933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Download and import libraries\n",
    "\n",
    "Download and install the latest versions of `torch`, `torchvision`, `transformers`, and `mlflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90ca5dd9-3ea5-4564-bc3e-2679699d4e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade torch transformers mlflow torchvision databricks-sdk\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe3dfcd-7a31-4185-a484-aea8e5dfb33e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import transformers\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "import datetime\n",
    "import json\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0342ed8c-da84-45e7-a70c-e4188eb12f45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set registry for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e99228-291d-479c-9c38-dcfbf798b6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following sets the model registry to use the Unity Catalog model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b254bee1-47db-40f9-9bf8-e8a512b24e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c94bd89-416d-410d-aa8e-4d4c116d140e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define PyFunc to load and create pipeline\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d396631d-c4c4-4de7-abc6-ea8dcac057f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define an MLflow `pyfunc` to take input text and return the NER results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11d1763-705c-4a5c-b9ea-b85fbe160ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define an mlflow pyfunc class which will be servable on a model serving endpoint.\n",
    "class ner_pyfunc(mlflow.pyfunc.PythonModel):\n",
    "  def __init__(self, hf_model_name : str) -> None:\n",
    "    self.model_name = hf_model_name\n",
    "  \n",
    "  # `load_context` is run once at initialization of the model on and endpoint. Here we will download and initialize the model.\n",
    "  def load_context(self, context : dict) -> None:\n",
    "    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n",
    "\n",
    "    # Create the NER pipeline, specify it will be put onto the GPU\n",
    "    self.ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=\"cuda:0\")\n",
    "  \n",
    "  # `predict` is called each time a batch of data is passed to the model serving endpoint.\n",
    "  def predict(self, context : dict, model_input : pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Run the NER pipeline\n",
    "    results = self.ner_pipeline(model_input[\"text\"].tolist())\n",
    "\n",
    "    # Convert outputs to a pandas dataframe\n",
    "    return pd.DataFrame({\"ner\" : pd.Series(results)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e183eb04-6d3f-46fc-a390-f8c1dd27dd67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e75b87c-413d-4fe5-bd6e-6f3aab7d3c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_model = ner_pyfunc(\"dslim/bert-base-NER-uncased\")\n",
    "_model.load_context({}) # This is done automatically on the serving endpoint, but in the notebook this needs to be done manually.\n",
    "\n",
    "# Create some test inputs.\n",
    "test_inputs = pd.DataFrame({\"text\" : [\"My name is Wolfgang and I live in Berlin\", \"My name is Colton, I work at Databricks.\"]})\n",
    "outputs = _model.predict({}, test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af760df7-2d4b-4e12-843a-8a488783c9e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac15969e-893b-4540-91d5-4d6d23fab3c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e48261-e922-4a01-974d-8fa2bb18a712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, create an MLflow signature to tell MLflow what inputs and outputs the model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "782388a5-8709-4ead-b532-8d55b22b2b12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load MLflow infer_signature\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Infer the signature from our test inputs and the associated outputs from the test model\n",
    "sig = infer_signature(test_inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b44f6a3-7b55-41fb-b781-19fd9d126ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create the dependencies list, so that your endpoint has all of the necessary libraries at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f1a8b1c-2808-4051-95be-5d7ba1b42491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the default pip requirements\n",
    "pip_reqs = mlflow.pyfunc.get_default_conda_env()\n",
    "# Add the libraries we need for our model\n",
    "pip_reqs[\"dependencies\"][-1][\"pip\"] += [\n",
    "  f\"torch=={torch.__version__.split('+')[0]}\",\n",
    "  f\"torchvision=={torchvision.__version__.split('+')[0]}\",\n",
    "  f\"transformers=={transformers.__version__}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5045c9-6eff-4041-bd36-15ded3cd5512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Register the model to the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1080ee42-0589-44c0-8b07-608230f8d5e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "  info = mlflow.pyfunc.log_model(\n",
    "    \"model\",\n",
    "    python_model=ner_pyfunc(\"dslim/bert-base-NER-uncased\"),\n",
    "    conda_env=pip_reqs,\n",
    "    input_example=test_inputs,\n",
    "    signature=sig,\n",
    "    registered_model_name=\"autobricks.default.ner_pyfunc\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f203ea1-4db2-41bb-aa8c-7827ebb7b90d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy model to Mosaic AI Model Serving endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16783668-058e-4b1b-a10d-01a7f8e5f095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Use the [Databricks Python SDK](https://databricks-sdk-py.readthedocs.io/en/latest/index.html) to create the model serving endpoint. Building the container and bringing it online can take some time, so the timeout is set to 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5356a749-1bd9-4bc6-b373-a9e4965c15bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a workspace client\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Create the serving endpoint\n",
    "w.serving_endpoints.create_and_wait(\n",
    "  name=\"ner-serving-endpoint\",\n",
    "  config=EndpointCoreConfigInput(\n",
    "    name=\"ner-serving-endpoint\",\n",
    "    served_entities=[\n",
    "      ServedEntityInput(\n",
    "        entity_name=\"autobricks.default.ner_pyfunc\",\n",
    "        entity_version=info.version,\n",
    "        name=\"ner\",\n",
    "        scale_to_zero_enabled=True,\n",
    "        workload_type=\"GPU_MEDIUM\",\n",
    "        workload_size=\"Small\"\n",
    "      )\n",
    "    ],\n",
    "  ),\n",
    "  timeout=datetime.timedelta(minutes=30)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d253079-4c24-4b6b-8ada-826fe67a9aea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, you can run a test query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98f96e2b-79e3-4d63-b2a7-ad8df7525e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = w.serving_endpoints.query(name=\"ner-serving-endpoint\", dataframe_records=json.loads(test_inputs.to_json(orient=\"records\")))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1fe82f7-3387-40c2-9fc3-7ed1fdd3bbb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Batch inference using `ai_query`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074def80-021e-47f9-9e35-2b436d3ed631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To run inference for several records at a time, you can perform batch inference using the `ai_query` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0a7a98-de11-4027-acea-2b4aeca04fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First create a PySpark dataframe\n",
    "df = (\n",
    "  spark.createDataFrame(\n",
    "    pd.DataFrame({\n",
    "      \"text\" : [\"My name is John, and I love databricks!\" for _ in range(1000)]\n",
    "    })\n",
    "  )\n",
    "  # Now add a column where we query our model serving endpoint\n",
    "  .withColumn(\"outputs\", F.expr(f\"\"\"ai_query(\n",
    "      \"ner-serving-endpoint\",\n",
    "      text\n",
    "    )\"\"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7897aec-80de-41cc-b206-a75e0298f734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Call the `display` function to execute the spark code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e48224-8620-4b83-a14c-dbdeccf614ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fc8aec4-4744-4674-ba38-e89d7db38cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now you have performed batch inference for 1000 data points on a BERT NER model serving endpoint!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "bert-batch-inference-ai-query",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
